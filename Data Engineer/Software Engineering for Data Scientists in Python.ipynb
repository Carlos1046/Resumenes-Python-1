{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Un científico de datos puede mejorar su habilidades con conceptos del campo de la ingeniería de software.\n",
    "\n",
    "Permitiendo reutilizar más fácilmente el código, compartir con colaboradores.\n",
    "\n",
    "En ocasiones tareas serán muy repetitivas, si tenemos funciones que nos apoyen podemos reciclar mucho código.\n",
    "\n",
    "Las ideas principales son la modularidad, documentación y pruebas automatizadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Engineering & Data Science\n",
    "\n",
    "Ejemplos de como puede mejorar nuestro flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Counter function into our environment\n",
    "from collections import Counter\n",
    "\n",
    "# View the documentation for Counter.most_common\n",
    "help(Counter.most_common)\n",
    "\n",
    "# use Counter to find the top 5 most common words\n",
    "top_5_words = Counter(words).most_common(5)\n",
    "\n",
    "# display the top 5 most common words\n",
    "print(top_5_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a Python Module\n",
    "\n",
    "Escribiendo nuestro primer paquete para reciclar funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing Classes\n",
    "\n",
    "La programación orientada a objetos es un elemento básico del desarrollo de Python.\n",
    "\n",
    "Al aprovechar las clases y la herencia, su paquete Python se convertirá en una herramienta mucho más poderosa para sus usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintainability\n",
    "\n",
    "¡Ahora ha escrito un paquete de Python completamente funcional para el análisis de texto!\n",
    "\n",
    "Para hacer que el mantenimiento de su proyecto sea lo más fácil posible, aprovecharemos las mejores prácticas en torno a conceptos como documentación y pruebas unitarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Complete the function's docstring\n",
    "def tokenize(text, regex=r'[a-zA-z]+'):\n",
    "  \"\"\"Split text into tokens using a regular expression\n",
    "\n",
    "  :param text: text to be tokenized\n",
    "  :param ____: regular expression used to match tokens using re.findall \n",
    "  :return: a list of resulting tokens\n",
    "\n",
    "  >>> tokenize('the rain in spain')\n",
    "  ['the','rain','in','spain']\n",
    "  \"\"\"\n",
    "  return re.findall(regex, text, flags=re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tokenize in module __main__:\n",
      "\n",
      "tokenize(text, regex='[a-zA-z]+')\n",
      "    Split text into tokens using a regular expression\n",
      "    \n",
      "    :param text: text to be tokenized\n",
      "    :param ____: regular expression used to match tokens using re.findall \n",
      "    :return: a list of resulting tokens\n",
      "    \n",
      "    >>> tokenize('the rain in spain')\n",
      "    ['the','rain','in','spain']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tokenize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
